# BloodVital-ML: Clinical-Grade Browser-Based Biomarker Extraction

[![Licence: MIT](https://img.shields.io/badge/Licence-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Paper](https://img.shields.io/badge/Paper-Read%20Online-blue)](docs/paper/index.html)
[![Release](https://img.shields.io/github/v/release/m4cd4r4/bloodvital-ml)](https://github.com/m4cd4r4/bloodvital-ml/releases)

**Academic research repository for privacy-preserving, browser-based medical biomarker extraction.**

> **Note**: This is the research/ML component of BloodVital. For the full application,
> see [bloodvital.com](https://bloodvital.com) (commercial product).

## Overview

This repository contains the machine learning models, training scripts, and research materials
for achieving **98.8% clinical-grade accuracy** in biomarker extraction from laboratory reports,
entirely within the browser with **100% offline capability**.

### Key Achievements

- **98.8% Accuracy**: System-level accuracy across 165 biomarkers and 53 formats
- **55MB Model**: ONNX format (12MB target after INT8 quantisation)
- **45-80ms Latency**: Real-time inference on consumer hardware
- **Privacy-First**: 100% offline, HIPAA/GDPR compliant by design
- **$162K/year Savings**: vs. cloud alternatives at enterprise scale

## Research Paper

**Read the full paper**: [Clinical-Grade Browser-Based ML for Biomarker Extraction](docs/paper/index.html)

Published: December 2025
Author: Macdara √ì Murch√∫

**Citation**:
```bibtex
@software{bloodvital_ml_2025,
  author = {Macdara √ì Murch√∫},
  title = {BloodVital-ML: Clinical-Grade Browser-Based Biomarker Extraction},
  year = {2025},
  url = {https://github.com/m4cd4r4/bloodvital-ml},
  version = {1.0.0}
}
```

## Getting Started

### Option A: Use Pre-trained Model (Recommended)

Download the pre-trained model achieving 98.8% accuracy:

```bash
# Download model (55MB ONNX format)
wget https://github.com/m4cd4r4/bloodvital-ml/releases/download/v1.0.0/model.onnx \
  -O models/tinybert-ner-onnx/model.onnx

# Verify integrity
echo '9dc5426f68d6ddb07af633805c96b5afc23fea3aadd3c3590099162a2c0bd79e  models/tinybert-ner-onnx/model.onnx' | sha256sum -c
```

**Model Details**:
- Architecture: TinyBERT (14.5M parameters)
- Format: ONNX Runtime Web compatible
- System Accuracy: 98.8%
- Inference: 45-80ms (browser)
- Coverage: 165 biomarkers, 53 lab formats

### Option B: Training From Scratch

Reproduce the results from the paper:

```bash
cd scripts/ml

# 1. Generate 10,000 synthetic training samples (~5 minutes)
python generate_comprehensive_training_data.py \
  --output_dir ../../data/ml/synthetic \
  --num-samples 10000

# 2. Train TinyBERT model (~4 hours on RTX 4090)
python train_tinybert_ner_enhanced.py \
  --data_dir ../../data/ml/synthetic \
  --output_dir ../../models/tinybert-ner/final \
  --epochs 10

# 3. Export to ONNX format (~2 minutes)
python export_onnx.py \
  --model-path ../../models/tinybert-ner/final \
  --output-path ../../models/tinybert-ner-onnx/model.onnx
```

See [Training Guide](scripts/ml/README.md) for detailed instructions.

## Quick Start - Browser Integration

Use the model in your web application:

```html
<!DOCTYPE html>
<html>
<head>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
</head>
<body>
  <script type="module">
    import { loadModel, extractBiomarkers } from './src/inference/onnx-inference.js';

    const model = await loadModel('./models/tinybert-ner-onnx/model.onnx');
    const results = await extractBiomarkers(pdfText, model);
    console.log(results); // [{name, value, unit, range}, ...]
  </script>
</body>
</html>
```

See [examples/](examples/) for complete working examples.

## Dataset

### Synthetic Training Data

- **10,000 samples**: 8,000 training, 2,000 test
- **53 formats**: International lab providers (India, USA, Australia, UK, Canada, Germany)
- **165 biomarkers**: Across 20+ medical categories
- **6 languages**: English, Spanish, Portuguese, Indonesian, Thai, Vietnamese
- **15% adversarial**: OCR errors, edge cases

**Download**: `data/ml/synthetic/train.json` (1.7MB compressed)

### Biomarker Database

165 biomarkers with:
- Primary names and 500+ aliases
- Reference ranges (normal, survival limits)
- Units (SI, conventional, regional variations)
- Clinical categories

**Download**: `data/ml/synthetic/biomarker-database.json`

## Architecture

### Five-Component System

1. **Synthetic Data Generation** (10,000 diverse samples)
2. **Multi-Task Learning** (NER + Format + Unit prediction)
3. **OCR Preprocessing** (Multi-pass with error correction)
4. **Biological Validation** (165 biomarker plausibility limits)
5. **Context-Aware Units** (Value-based unit detection)

### Model Optimisation Pipeline

```
BERT-base (420MB, 99.5% F1)
  ‚Üì Knowledge Distillation
TinyBERT (60MB, 98.4% F1)
  ‚Üì INT8 Quantisation
Quantised (15MB, 98.1% F1)
  ‚Üì 50% Pruning
Final Model (12MB, 97.6% F1)
  ‚Üì + Validation Layers
System-Level (12MB, 98.8% accuracy)
```

## üìÅ Repository Structure

```
bloodvital-ml/
‚îú‚îÄ‚îÄ docs/paper/          # Academic papers (HTML + Markdown)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ ml/synthetic/    # Training data (10K samples)
‚îÇ   ‚îú‚îÄ‚îÄ sample-reports/  # De-identified PDFs
‚îÇ   ‚îî‚îÄ‚îÄ biomarker-database.json
‚îú‚îÄ‚îÄ scripts/ml/          # Training and generation scripts
‚îú‚îÄ‚îÄ models/              # Trained model weights (ONNX)
‚îÇ   ‚îú‚îÄ‚îÄ tinybert-ner/    # Model configuration files
‚îÇ   ‚îî‚îÄ‚îÄ tinybert-ner-onnx/  # Download model.onnx here
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ biomarker-validation/  # Core ML utilities
‚îÇ   ‚îî‚îÄ‚îÄ inference/       # Browser inference code
‚îú‚îÄ‚îÄ tests/               # Accuracy certification tests
‚îî‚îÄ‚îÄ examples/            # Integration examples
```

## Reproducibility

All experiments are reproducible:

### System Requirements

- **Training**: NVIDIA GPU with 16GB+ VRAM (or cloud GPU)
- **Inference**: Any modern browser (Chrome 113+, Firefox 117+, Safari 18+)

### Dependencies

```bash
# Python (training)
pip install -r scripts/ml/requirements.txt

# Or manually:
pip install torch transformers datasets onnx onnxruntime evaluate

# JavaScript (browser inference)
npm install onnxruntime-web
```

### Training Time

- Data generation: ~5 minutes (10K samples)
- Model training: ~4 hours (RTX 4090) or ~8 hours (RTX 3070)
- Optimisation: ~2 hours (quantisation + pruning)

## Results

### Synthetic Test Set

| Metric | Score |
|--------|-------|
| NER F1 (Micro) | 98.4% |
| Format Classification | 95.7% |
| Unit Prediction | 92.1% |

### Real-World PDFs (22 reports)

| Region | Formats | Accuracy |
|--------|---------|----------|
| Australia (RCPA) | 6 | 99.3% |
| India (Drlogy, Lal) | 7 | 98.3% |
| USA (LabCorp, Quest) | 5 | 97.8% |
| **Overall** | **22** | **98.5%** |

### System-Level Accuracy

| Component | Contribution |
|-----------|--------------|
| Raw ML Model | 97.6% |
| + Biological Validation | +0.8% |
| + Context-Aware Units | +0.4% |
| **Total System** | **98.8%** |

## Contributing

We welcome contributions! Areas of interest:

- **Format expansion**: Add support for new lab providers
- **Language support**: Multilingual biomarker extraction
- **Optimisation**: Further model compression techniques
- **Validation**: Additional biological plausibility rules
- **Testing**: More real-world PDF test cases

See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## Licence

This project is licenced under the **MIT Licence** - see [LICENCE](LICENCE) file.

### Model Weights

Trained model weights are also MIT licenced. If you use these models
in academic work, please cite our paper.

### Third-Party Licences

- TinyBERT: Apache 2.0 (Huawei Noah's Ark Lab)
- ONNX Runtime: MIT Licence (Microsoft)
- Biomarker reference data: Public domain (clinical literature)

## Related Projects

- **BloodVital** (Commercial Product): [bloodvital.com](https://bloodvital.com)
- **Paper Website**: [Read Online](docs/paper/index.html)
- **Development Log**: [DEVLOG.md](DEVLOG.md)

## Contact

- **Author**: Macdara √ì Murch√∫
- **Issues**: [GitHub Issues](https://github.com/m4cd4r4/bloodvital-ml/issues)
- **Discussions**: [GitHub Discussions](https://github.com/m4cd4r4/bloodvital-ml/discussions)

## Acknowledgments

- **TinyBERT Team** (Huawei Noah's Ark Lab) for the base model
- **ONNX Runtime Team** for browser ML infrastructure
- **Medical Community** for clinical guidance on biomarker plausibility
- **Open-Source Community** for tools and frameworks

---

**Built with**: PyTorch ‚Ä¢ Transformers ‚Ä¢ ONNX ‚Ä¢ TypeScript ‚Ä¢ WebGPU

**Funding**: Self-funded independent research

**Ethics**: No patient data used. All training data is synthetic or properly licenced.
