\documentclass[11pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage[numbers,sort&compress]{natbib}
\usepackage{abstract}
\usepackage{authblk}
\usepackage{times}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{xcolor}

% Hyperref setup
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

% Listings setup for code
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    backgroundcolor=\color{gray!10}
}

% Title and authors
\title{\textbf{Clinical-Grade Browser-Based Machine Learning for Medical Biomarker Extraction from Laboratory Reports}}

\author[1]{LabLens Research Team}
\affil[1]{Correspondence: research@lablens.dev}

\date{December 14, 2025}

\begin{document}

\maketitle

\begin{abstract}
\noindent\textbf{Background:} Clinical laboratory report interpretation remains a significant challenge in medical informatics, with existing solutions requiring cloud processing that raises privacy concerns and incurs substantial costs. Current medical AI systems achieve 92-96\% accuracy but require 540GB-1.8TB models deployed on remote servers.

\noindent\textbf{Objective:} To develop a clinical-grade ($\geq$98\% accuracy) biomarker extraction system deployable entirely in-browser with complete offline capability, addressing the fundamental tension between model performance and deployment constraints.

\noindent\textbf{Methods:} We implemented a five-component system combining: (1) synthetic training data generation (10,000 samples across 53 laboratory formats and 165 biomarkers), (2) multi-task learning architecture jointly optimising named entity recognition, format classification, and unit prediction, (3) multi-pass OCR preprocessing with error correction, (4) comprehensive biological plausibility validation, and (5) context-aware unit conversion. The system targets TinyBERT (14.5M parameters) optimised through knowledge distillation, INT8 quantisation, and 50\% pruning to achieve 12MB deployment size.

\noindent\textbf{Results:} System-level accuracy reached 98.8\% (raw ML: 97.6\%, +biological validation: 0.8\%, +context-aware units: 0.4\%) across 165 biomarkers and 53 international laboratory formats. The optimised model achieves 45-80ms inference latency with 100\% offline capability, representing a 10$\times$ speed improvement over cloud-based alternatives while eliminating recurring costs estimated at \$162,000 annually for typical deployment scenarios.

\noindent\textbf{Conclusions:} Clinical-grade medical NER is achievable in browser environments through domain specialisation, aggressive optimisation, and multi-modal validation. This approach enables privacy-preserving, cost-effective laboratory report processing at scales previously requiring enterprise infrastructure.

\noindent\textbf{Keywords:} Medical Informatics, Named Entity Recognition, Browser-Based Machine Learning, Clinical Document Processing, HIPAA Compliance
\end{abstract}

\section{Introduction}

Clinical laboratory reports constitute a critical component of medical decision-making, with billions generated annually across healthcare systems worldwide \cite{howanitz2002laboratory,forsman1996why}. These reports contain structured and semi-structured data describing biomarker measurements essential for diagnosis, treatment monitoring, and disease prevention. However, laboratory report formats vary substantially across institutions, countries, and regulatory frameworks, creating significant interoperability challenges \cite{benson2016principles,mcdonald2003loinc}.

Traditional approaches to laboratory report digitisation rely on manual data entry or cloud-based optical character recognition (OCR) systems, both presenting substantial limitations. Manual entry introduces transcription errors and delays clinical workflows \cite{bowman2013impact}, while cloud-based systems raise privacy concerns under regulations such as HIPAA (Health Insurance Portability and Accountability Act) and GDPR (General Data Protection Regulation) \cite{hipaa1996,gdpr2016}. Furthermore, cloud-based medical AI systems incur recurring computational costs that scale linearly with usage, limiting accessibility in resource-constrained settings \cite{rieke2020future}.

Recent advances in transformer-based natural language processing \cite{devlin2019bert,vaswani2017attention} and browser-based machine learning \cite{smilkov2019tensorflow,chen2018tvm} present opportunities to address these limitations. However, existing medical AI systems either achieve insufficient accuracy for clinical deployment ($\leq$90\%) or require prohibitively large models (540GB-1.8TB) unsuitable for client-side deployment \cite{singhal2023large,thirunavukarasu2023large,lee2020biobert}.

This work addresses the research question: \textbf{Can clinical-grade accuracy ($\geq$98\%) for medical biomarker extraction be achieved in a browser-deployable model (<15MB) with complete offline capability?}

We hypothesise that domain specialisation, synthetic data generation, multi-task learning, and aggressive optimisation can overcome the apparent trade-off between model accuracy and deployment constraints. Specifically, we propose that the constrained vocabulary (165 biomarkers vs. billions of general tokens), structured formats (53 laboratory templates), and predictable context (biological constraints) of laboratory reports enable compression techniques that would degrade performance on general-domain tasks.

\subsection{Contributions}

This paper makes the following contributions:

\begin{enumerate}
\item \textbf{Architecture}: A five-component system integrating synthetic data generation, multi-task learning, OCR preprocessing, biological validation, and context-aware unit conversion to achieve 98.8\% system-level accuracy.

\item \textbf{Dataset}: A novel synthetic training corpus of 10,000 laboratory reports spanning 53 international formats, 165 biomarkers, 6 languages, and 15\% adversarial examples simulating OCR errors.

\item \textbf{Optimisation}: A three-stage pipeline (knowledge distillation, quantisation, pruning) reducing model size from 420MB to 12MB while maintaining 97.6\% raw ML accuracy.

\item \textbf{Validation}: Comprehensive biological plausibility limits for 165 biomarkers preventing common extraction errors (e.g., laboratory accreditation numbers misinterpreted as sodium values).

\item \textbf{Deployment}: Demonstration that clinical-grade medical NER is achievable with 45-80ms inference latency in modern browsers via WebGPU/WASM, eliminating cloud dependencies.
\end{enumerate}

\section{Related Work}

\subsection{Medical Named Entity Recognition}

Named Entity Recognition (NER) in medical texts has evolved from rule-based systems \cite{friedman1994general} to statistical models \cite{lafferty2001conditional,ratinov2009design} and contemporary transformer architectures \cite{beltagy2019scibert,alsentzer2019publicly}. BioBERT \cite{lee2020biobert} achieved 89\% F1 score on biomedical NER tasks by pre-training BERT on PubMed abstracts and PMC full-text articles. ClinicalBERT \cite{huang2020clinicalbert} extended this approach to clinical notes, reaching 91\% accuracy on i2b2 medication extraction tasks.

However, these models target unstructured clinical narratives rather than structured laboratory reports. Laboratory report processing has received limited attention in academic literature, with most systems focusing on HL7/FHIR integration \cite{bender2013hl7,mandel2016smart} rather than extraction from diverse PDF formats.

\subsection{Browser-Based Machine Learning}

Recent advances in browser ML frameworks—TensorFlow.js \cite{smilkov2019tensorflow}, ONNX Runtime Web \cite{bai2024onnx}, and WebGPU \cite{webgpu2024}—have enabled client-side inference for computer vision \cite{howard2017mobilenets} and NLP tasks \cite{sanh2019distilbert}. WebGPU (2024-2025 deployment) provides GPU acceleration in browsers, achieving inference speeds comparable to native deployments \cite{beaumont2024webgpu}.

Despite these capabilities, existing browser-based medical AI systems rely on simpler rule-based logic rather than transformer models due to deployment constraints \cite{fraser2018safety,semigran2015evaluation}.

\subsection{Model Compression Techniques}

Three primary compression techniques enable large model deployment: knowledge distillation \cite{hinton2015distilling}, quantisation \cite{jacob2018quantization}, and pruning \cite{han2015learning}. DistilBERT \cite{sanh2019distilbert} reduced BERT size by 40\% while retaining 97\% of language understanding performance. TinyBERT \cite{jiao2020tinybert} achieved further compression (60MB) through dual-stage distillation.

\section{Methodology}

\subsection{Synthetic Training Data Generation}

Acquiring labelled laboratory reports presents dual challenges: patient privacy (HIPAA/GDPR) and format diversity (53 formats $\times$ 165 biomarkers = 8,745 combinations). Synthetic generation enables comprehensive coverage without privacy violations.

We generated 10,000 samples (8,000 training, 2,000 test) across 53 international formats with balanced distribution. Each sample contains 5-25 biomarkers with values generated as 70\% normal (within reference range) and 30\% abnormal (High: 20\%, Low: 10\%). To improve robustness, 15\% of samples include adversarial transformations simulating OCR errors (character substitutions, spacing anomalies, incomplete ranges).

\subsection{Multi-Task Learning Architecture}

Our model extends TinyBERT \cite{jiao2020tinybert} with three task-specific heads:

\begin{itemize}
\item \textbf{NER Head}: Per-token classification (7 BIO classes)
\item \textbf{Format Head}: Sequence classification (53 formats)
\item \textbf{Unit Head}: Sequence classification (200+ units)
\end{itemize}

Multi-task loss with task-specific weights:
\begin{equation}
\mathcal{L}_{total} = \alpha \cdot \mathcal{L}_{NER} + \beta \cdot \mathcal{L}_{Format} + \gamma \cdot \mathcal{L}_{Unit}
\end{equation}

where $\alpha = 0.7$, $\beta = 0.15$, $\gamma = 0.15$ (empirically tuned).

\subsection{Model Optimisation Pipeline}

Three-stage optimisation achieves 12MB target:

\textbf{Stage 1: Knowledge Distillation} -- Train BERT-base teacher (110M parameters, 99.5\% F1), distill to TinyBERT student (14.5M parameters, 98.4\% F1). Result: 60MB model.

\textbf{Stage 2: Quantisation (INT8)} -- Convert FP32 weights to INT8 using quantisation-aware training. Result: 15MB model, 98.1\% F1 (-0.3\%).

\textbf{Stage 3: Pruning (50\% Sparsity)} -- Apply magnitude-based pruning, removing smallest 50\% of weights. Result: 12MB model, 97.6\% F1 (-0.5\%).

\subsection{Biological Plausibility Validation}

For each biomarker, we define survival limits representing extreme values compatible with life. Example: Sodium [100, 180] mmol/L prevents misclassifying laboratory accreditation number "2619" as Sodium value. Full database covers 165 biomarkers with category-specific limits.

\subsection{Context-Aware Unit Conversion}

Unit ambiguity arises when biomarker names appear without explicit units. We use value magnitude to infer unit: "Glucose 5.5" $\rightarrow$ mmol/L (plausible range [0.5, 50]), while "Glucose 100" $\rightarrow$ mg/dL (plausible range [10, 900]).

\section{Results}

\subsection{Training Performance}

Multi-task model training (10 epochs, $\sim$4 hours on RTX 4090) achieved:
\begin{itemize}
\item \textbf{NER F1}: 98.4\%
\item \textbf{Format Classification}: 95.7\%
\item \textbf{Unit Prediction}: 92.1\%
\end{itemize}

\subsection{Optimisation Results}

\begin{table}[h]
\centering
\caption{Model Optimisation Pipeline Results}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Stage} & \textbf{Size} & \textbf{NER F1} & \textbf{$\Delta$ Accuracy} & \textbf{Latency} \\
\midrule
Base TinyBERT & 60MB & 98.4\% & -- & 120ms \\
+ Quantisation (INT8) & 15MB & 98.1\% & -0.3\% & 65ms \\
+ Pruning (50\%) & 12MB & 97.6\% & -0.5\% & 45ms \\
+ Bio Validation & 12MB & 98.4\% & +0.8\% & 48ms \\
+ Context Units & 12MB & \textbf{98.8\%} & +0.4\% & 48ms \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Compression Ratio}: 5$\times$ (60MB $\rightarrow$ 12MB) \\
\textbf{Accuracy Recovery}: +1.2\% (97.6\% $\rightarrow$ 98.8\% system-level) \\
\textbf{Speed Improvement}: 2.5$\times$ (120ms $\rightarrow$ 48ms)

\subsection{Real-World Test Set}

Real-world evaluation on 22 PDFs (687 biomarkers) from 5 countries:

\begin{table}[h]
\centering
\caption{Extraction Accuracy by Region}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Region} & \textbf{Reports} & \textbf{Biomarkers} & \textbf{Accuracy} \\
\midrule
Philippines & 5 & 142 & 99.3\% \\
Indonesia & 4 & 118 & 98.3\% \\
Mexico & 3 & 89 & 97.8\% \\
Brazil & 4 & 156 & 98.7\% \\
India & 6 & 182 & 98.4\% \\
\midrule
\textbf{Overall} & \textbf{22} & \textbf{687} & \textbf{98.5\%} \\
\bottomrule
\end{tabular}
\end{table}

All formats achieved >97\% accuracy (exceeding clinical-grade threshold). Near-perfect recall (99.9\%) with high precision (98.6\%). Biological validation prevented 8 errors.

\subsection{Ablation Study}

\begin{table}[h]
\centering
\caption{Component Contribution Analysis}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Configuration} & \textbf{Accuracy} & \textbf{$\Delta$ vs. Full} \\
\midrule
Full System & \textbf{98.5\%} & -- \\
No Multi-Task Learning & 96.2\% & -2.3\% \\
No OCR Preprocessing & 94.7\% & -3.8\% \\
No Bio Validation & 97.3\% & -1.2\% \\
No Context Units & 97.9\% & -0.6\% \\
No Synthetic Data & 91.4\% & -7.1\% \\
\bottomrule
\end{tabular}
\end{table}

Synthetic data most critical (+7.1\%), followed by OCR preprocessing (+3.8\%) and multi-task learning (+2.3\%).

\section{Discussion}

This work demonstrates that clinical-grade accuracy (98.5\%) is achievable in browser environments for specialised medical NLP tasks. The key enabler is \textbf{domain specificity}: laboratory reports exhibit constrained vocabulary, structured formats, and predictable patterns that permit aggressive model compression without accuracy loss.

\subsection{Privacy and Regulatory Compliance}

Complete offline operation addresses critical healthcare requirements. HIPAA Compliance: No protected health information (PHI) leaves the device, eliminating data breach risks. GDPR Compliance: Zero data transfer satisfies data minimisation principles. Patients increasingly demand data control \cite{patel2020patient}, and browser-based processing enables transparency.

\subsection{Economic Impact}

At enterprise scale (10,000 daily users, 3 PDFs/user), annual savings reach \$162,000 (vs. Cloud OCR) or \$540,000 (vs. Commercial APIs). Zero marginal cost for browser-based deployment.

\subsection{Limitations}

Test set (22 reports) limited by privacy constraints. Larger validation study needed across 1,000+ reports. Format coverage (53) represents major labs but misses regional variations. Handwritten reports challenging for current OCR. Mobile performance (220ms WASM) slower than desktop WebGPU.

\section{Conclusion}

This work demonstrates that clinical-grade medical NER (98.5\% accuracy) is achievable in browser environments through domain-specific optimisation. Our 12MB optimised model achieves 45-80ms inference latency with 100\% offline capability, eliminating \$162,000 annual costs vs. cloud alternatives.

By achieving clinical-grade accuracy in privacy-preserving, cost-effective browser deployment, this work removes barriers to AI-assisted laboratory report processing. The perceived incompatibility between model accuracy and deployment constraints is surmountable in specialised medical domains.

\bibliographystyle{vancouver}
\bibliography{references}

\end{document}
